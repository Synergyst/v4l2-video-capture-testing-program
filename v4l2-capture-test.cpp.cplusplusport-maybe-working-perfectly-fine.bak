#include <algorithm>
#include <atomic>
#include <cassert>
#include <chrono>
#include <cmath>
#include <cstdint>
#include <cstdio>
#include <cstring>
#include <exception>
#include <future>
#include <iostream>
#include <stdexcept>
#include <string>
#include <system_error>
#include <thread>
#include <vector>

#include <errno.h>
#include <fcntl.h>
#include <libv4l2.h>
#include <linux/videodev2.h>
#include <popt.h>
#include <sys/ioctl.h>
#include <sys/mman.h>
#include <sys/select.h>
#include <sys/stat.h>
#include <sys/time.h>
#include <sys/types.h>
#include <unistd.h>

using std::cerr;
using std::cout;
using std::endl;

// Constants formerly macros
constexpr int V4L_ALLFORMATS = 3;
constexpr int V4L_RAWFORMATS = 1;
constexpr int V4L_COMPFORMATS = 2;

static int defaultWidth = 1920;
static int defaultHeight = 1080;

static double allDevicesTargetFramerate = 240.0;
static bool isDualInput = false;
static std::atomic<bool> shouldLoop{false};
static std::future<int> background_task_cap_main;
static std::future<int> background_task_cap_alt;
static std::vector<std::string> devNames;

static inline std::string trim_copy(const std::string& s) {
    const char* ws = " \t\r\n";
    const auto b = s.find_first_not_of(ws);
    if (b == std::string::npos) return std::string();
    const auto e = s.find_last_not_of(ws);
    return s.substr(b, e - b + 1);
}

static bool doubles_equal(double a, double b, double epsilon = 0.001) {
    return std::fabs(a - b) < epsilon;
}

class MicroStopwatch {
    std::chrono::high_resolution_clock::time_point start_time;
public:
    void start() { start_time = std::chrono::high_resolution_clock::now(); }
    double elapsedMicros() const {
        auto now = std::chrono::high_resolution_clock::now();
        std::chrono::duration<double, std::micro> diff = now - start_time;
        return diff.count();
    }
};

static void throw_errno(const char* what) {
    throw std::system_error(errno, std::generic_category(), what);
}

static int xioctl(int fh, int request, void* arg) {
    int r;
    do {
        r = ioctl(fh, request, arg);
    } while (r == -1 && errno == EINTR);
    return r;
}

class MMapBuffer {
public:
    void* start = nullptr;
    size_t length = 0;

    MMapBuffer() = default;
    MMapBuffer(int fd, const v4l2_buffer& buf) {
        length = buf.length;
        start = mmap(nullptr, length, PROT_READ | PROT_WRITE, MAP_SHARED, fd, buf.m.offset);
        if (start == MAP_FAILED) {
            start = nullptr;
            throw_errno("mmap");
        }
    }
    MMapBuffer(const MMapBuffer&) = delete;
    MMapBuffer& operator=(const MMapBuffer&) = delete;
    MMapBuffer(MMapBuffer&& other) noexcept : start(other.start), length(other.length) {
        other.start = nullptr;
        other.length = 0;
    }
    MMapBuffer& operator=(MMapBuffer&& other) noexcept {
        if (this != &other) {
            cleanup();
            start = other.start;
            length = other.length;
            other.start = nullptr;
            other.length = 0;
        }
        return *this;
    }
    ~MMapBuffer() { cleanup(); }
private:
    void cleanup() {
        if (start) {
            munmap(start, length);
            start = nullptr;
            length = 0;
        }
    }
};

class Device {
public:
    explicit Device(std::string path,
                    int idx,
                    int forceFmt,
                    double targetFps,
                    bool isTc358743)
        : devicePath(std::move(path)),
          index(idx),
          force_format(forceFmt),
          targetFramerate(targetFps),
          isTC358743(isTc358743) {}

    ~Device() {
        try {
            // Best-effort to stop stream; ignore errors on shutdown
            if (fd >= 0) {
                // STREAMOFF is optional; close will stop the stream anyway.
                // v4l2_buf_type t = V4L2_BUF_TYPE_VIDEO_CAPTURE;
                // xioctl(fd, VIDIOC_STREAMOFF, &t);
            }
        } catch (...) {}
        // buffers unmapped via MMapBuffer destructors
        if (fd >= 0) {
            close(fd);
            fd = -1;
        }
    }

    void init() {
        stage1_open_and_configure();
        stage2_map_and_stream();
        outputFrame.assign(static_cast<size_t>(startingSize), 0);
    }

    int get_frame() {
        // Wait for the device to become ready
        fd_set fds;
        FD_ZERO(&fds);
        FD_SET(fd, &fds);

        // timeout: 2x the nominal frame delay
        long usec = static_cast<long>(std::max(20000.0, frameDelayMicros * 2.0));
        struct timeval tv{};
        tv.tv_sec = usec / 1000000;
        tv.tv_usec = usec % 1000000;

        int r = select(fd + 1, &fds, nullptr, nullptr, &tv);
        if (r == -1) {
            if (errno == EINTR) return 0;
            cerr << "[cap" << index << "] select error: " << std::strerror(errno) << endl;
            shouldLoop.store(false);
            return 1;
        }
        if (r == 0) {
            cerr << "[cap" << index << "] select timeout\n";
            shouldLoop.store(false);
            return 1;
        }

        v4l2_buffer buf{};
        buf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
        buf.memory = V4L2_MEMORY_MMAP;

        if (xioctl(fd, VIDIOC_DQBUF, &buf) == -1) {
            if (errno == EAGAIN) {
                cerr << "[cap" << index << "] EAGAIN\n";
                return 0;
            }
            cerr << "[cap" << index << "] VIDIOC_DQBUF error " << errno << ", " << std::strerror(errno) << endl;
            shouldLoop.store(false);
            return 1;
        }

        if (buf.index >= buffers.size()) {
            cerr << "[cap" << index << "] buffer index out of range\n";
            shouldLoop.store(false);
            return 1;
        }

        // Copy frame into output buffer
        const MMapBuffer& b = buffers[buf.index];
        std::memcpy(outputFrame.data(), b.start, std::min(b.length, outputFrame.size()));

        // Re-queue the buffer
        if (xioctl(fd, VIDIOC_QBUF, &buf) == -1) {
            throw_errno("VIDIOC_QBUF");
        }

        return 0;
    }

    // Exposed fields for use by main loop (read-only after init)
    int index = 0;
    int startingWidth = defaultWidth;
    int startingHeight = defaultHeight;
    int startingSize = startingWidth * startingHeight * 3; // bytes
    int bytesPerPixel = 3;
    int framerate = 30;
    double frameDelayMicros = 1'000'000.0 / 30.0;
    double frameDelayMillis = 1'000.0 / 30.0;
    double targetFrameDelayMicros = frameDelayMicros;
    double targetFrameDelayMillis = frameDelayMillis;
    double framerateDivisor = 1.0;
    double targetFramerate = 30.0;
    bool realAndTargetRatesMatch = true;

    std::vector<unsigned char> outputFrame;

    const std::string& path() const { return devicePath; }

private:
    std::string devicePath;
    int fd = -1;
    int force_format = 0;
    bool isTC358743 = true;

    v4l2_requestbuffers req{};
    std::vector<MMapBuffer> buffers;

    void stage1_open_and_configure() {
        cerr << "\n[cap" << index << "] Starting V4L2 capture testing program with the following V4L2 device: " << devicePath << endl;

        struct stat st{};
        if (stat(devicePath.c_str(), &st) == -1) {
            throw std::runtime_error("[cap" + std::to_string(index) + "] Cannot identify '" + devicePath + "': " + std::to_string(errno) + ", " + std::strerror(errno));
        }
        if (!S_ISCHR(st.st_mode)) {
            throw std::runtime_error("[cap" + std::to_string(index) + "] " + devicePath + " is not a character device");
        }

        fd = open(devicePath.c_str(), O_RDWR | O_NONBLOCK, 0);
        if (fd == -1) {
            throw_errno(("open " + devicePath).c_str());
        }
        cerr << "[cap" << index << "] Opened V4L2 device: " << devicePath << endl;

        v4l2_capability cap{};
        if (xioctl(fd, VIDIOC_QUERYCAP, &cap) == -1) {
            if (errno == EINVAL) {
                throw std::runtime_error("[cap" + std::to_string(index) + "] " + devicePath + " is no V4L2 device");
            }
            throw_errno("VIDIOC_QUERYCAP");
        }
        if (!(cap.capabilities & V4L2_CAP_VIDEO_CAPTURE)) {
            throw std::runtime_error("[cap" + std::to_string(index) + "] " + devicePath + " is no video capture device");
        }

        // Try cropping to default rectangle if supported
        v4l2_cropcap cropcap{};
        cropcap.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
        if (xioctl(fd, VIDIOC_CROPCAP, &cropcap) == 0) {
            v4l2_crop crop{};
            crop.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
            crop.c = cropcap.defrect;
            // Ignore cropping errors
            xioctl(fd, VIDIOC_S_CROP, &crop);
        }

        v4l2_format fmt{};
        fmt.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
        cerr << "[cap" << index << "] Forcing format for " << devicePath << " to: " << force_format << endl;

        if (force_format) {
            if (force_format == 3) {
                bytesPerPixel = 3;
                fmt.fmt.pix.width = startingWidth;
                fmt.fmt.pix.height = startingHeight;
                fmt.fmt.pix.pixelformat = V4L2_PIX_FMT_RGB24;
                fmt.fmt.pix.field = V4L2_FIELD_NONE;
            } else if (force_format == 2) {
                bytesPerPixel = 2;
                fmt.fmt.pix.width = startingWidth;
                fmt.fmt.pix.height = startingHeight;
                fmt.fmt.pix.pixelformat = V4L2_PIX_FMT_UYVY;
                fmt.fmt.pix.field = V4L2_FIELD_NONE;
            } else if (force_format == 1) {
                bytesPerPixel = 1;
                fmt.fmt.pix.width = startingWidth;
                fmt.fmt.pix.height = startingHeight;
                fmt.fmt.pix.pixelformat = V4L2_PIX_FMT_GREY;
                fmt.fmt.pix.field = V4L2_FIELD_NONE;
            }
            if (xioctl(fd, VIDIOC_S_FMT, &fmt) == -1) {
                throw_errno("VIDIOC_S_FMT");
            }
        } else {
            if (xioctl(fd, VIDIOC_G_FMT, &fmt) == -1) {
                throw_errno("VIDIOC_G_FMT");
            }
            // Infer bytesPerPixel if possible
            switch (fmt.fmt.pix.pixelformat) {
                case V4L2_PIX_FMT_RGB24: bytesPerPixel = 3; break;
                case V4L2_PIX_FMT_UYVY:  bytesPerPixel = 2; break;
                case V4L2_PIX_FMT_YUYV:  bytesPerPixel = 2; break;
                case V4L2_PIX_FMT_GREY:  bytesPerPixel = 1; break;
                default:                 bytesPerPixel = 2; break;
            }
        }

        // Paranoia per V4L2 docs
        unsigned int min = fmt.fmt.pix.width * 2;
        if (fmt.fmt.pix.bytesperline < min) fmt.fmt.pix.bytesperline = min;
        min = fmt.fmt.pix.bytesperline * fmt.fmt.pix.height;
        if (fmt.fmt.pix.sizeimage < min) fmt.fmt.pix.sizeimage = min;

        // Request MMAP buffers
        req = {};
        req.count = 4;
        req.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
        req.memory = V4L2_MEMORY_MMAP;
        if (xioctl(fd, VIDIOC_REQBUFS, &req) == -1) {
            if (errno == EINVAL) {
                throw std::runtime_error("[cap" + std::to_string(index) + "] " + devicePath + " does not support memory mapping");
            }
            throw_errno("VIDIOC_REQBUFS");
        }
        if (req.count < 2) {
            throw std::runtime_error("[cap" + std::to_string(index) + "] Insufficient buffer memory on " + devicePath);
        }
    }

    void stage2_map_and_stream() {
        if (!isTC358743) {
            throw std::runtime_error("[cap" + std::to_string(index) + "] Fatal: Only the TC358743 is supported for now. Support for general camera inputs will need to be added.");
        }

        // Map buffers
        buffers.clear();
        buffers.reserve(req.count);
        for (unsigned int i = 0; i < req.count; ++i) {
            v4l2_buffer buf{};
            buf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
            buf.memory = V4L2_MEMORY_MMAP;
            buf.index = i;
            if (xioctl(fd, VIDIOC_QUERYBUF, &buf) == -1) {
                throw_errno("VIDIOC_QUERYBUF");
            }
            buffers.emplace_back(fd, buf);
        }

        // Query DV timings or fallback to standard
        v4l2_dv_timings timings{};
        int ret = xioctl(fd, VIDIOC_QUERY_DV_TIMINGS, &timings);
        if (ret >= 0) {
            cerr << "[cap" << index << "] QUERY_DV_TIMINGS for " << devicePath
                 << ": " << timings.bt.width << "x" << timings.bt.height
                 << "x" << bytesPerPixel << " pixclk " << timings.bt.pixelclock << endl;

            startingWidth = timings.bt.width;
            startingHeight = timings.bt.height;

            // Set them explicitly
            if (xioctl(fd, VIDIOC_S_DV_TIMINGS, &timings) < 0) {
                cerr << "[cap" << index << "] Failed to set DV timings\n";
                throw std::runtime_error("Failed to set DV timings");
            } else {
                const v4l2_bt_timings* bt = &timings.bt;
                const double tot_height =
                    static_cast<double>(bt->height + bt->vfrontporch + bt->vsync + bt->vbackporch +
                                        bt->il_vfrontporch + bt->il_vsync + bt->il_vbackporch);
                const double tot_width =
                    static_cast<double>(bt->width + bt->hfrontporch + bt->hsync + bt->hbackporch);
                if (tot_height > 0.0 && tot_width > 0.0) {
                    framerate = static_cast<int>(
                        static_cast<double>(bt->pixelclock) / (tot_width * tot_height));
                } else {
                    framerate = 30;
                }
            }
        } else {
            v4l2_std_id std{};
            if (ioctl(fd, VIDIOC_QUERYSTD, &std) >= 0) {
                if (xioctl(fd, VIDIOC_S_STD, &std) < 0) {
                    cerr << "[cap" << index << "] Failed to set standard\n";
                    throw std::runtime_error("Failed to set standard");
                } else {
                    // SD video - assume 50Hz / 25fps
                    framerate = 25;
                }
            }
        }

        startingSize = startingWidth * startingHeight * bytesPerPixel;

        // Compute timing and throughput metadata
        if (targetFramerate > framerate) {
            targetFramerate = static_cast<double>(framerate);
        }
        framerateDivisor = static_cast<double>(framerate) / targetFramerate;
        frameDelayMicros = 1'000'000.0 / static_cast<double>(framerate);
        frameDelayMillis = 1'000.0 / static_cast<double>(framerate);
        targetFrameDelayMicros = frameDelayMicros * framerateDivisor;
        targetFrameDelayMillis = frameDelayMillis * framerateDivisor;

        int rawInputThroughput = static_cast<int>(
            static_cast<float>(static_cast<float>(framerate) * static_cast<float>(startingSize) / 125000.0f));
        int rawOutputThroughput = static_cast<int>(
            (static_cast<float>(framerate) * static_cast<float>(startingSize) / 125000.0f) / static_cast<float>(framerateDivisor));

        realAndTargetRatesMatch = doubles_equal(frameDelayMicros, targetFrameDelayMicros);

        cerr << "[cap" << index << "] device_name: " << devicePath
             << ", startingWidth: " << startingWidth
             << ", startingHeight: " << startingHeight
             << ", bytesPerPixel: " << bytesPerPixel
             << ", startingSize: " << startingSize
             << ", framerate(actual): " << framerate
             << ", framerateDivisor: " << framerateDivisor
             << ", targetFramerate: " << targetFramerate
             << ", frameDelayMicros: " << frameDelayMicros
             << ", frameDelayMillis: " << frameDelayMillis
             << ", targetFrameDelayMicros: " << targetFrameDelayMicros
             << ", targetFrameDelayMillis: " << targetFrameDelayMillis
             << ", realAndTargetRatesMatch: " << (realAndTargetRatesMatch ? 1 : 0)
             << endl;

        cerr << "[cap" << index << "] device_name: " << devicePath
             << ", isTC358743: " << (isTC358743 ? 1 : 0)
             << ", rawInputThroughput: ~" << rawInputThroughput << "Mb/~"
             << static_cast<int>(static_cast<double>(rawInputThroughput) / 8.389) << "MiB/~"
             << (rawInputThroughput / 8) << "MB/sec, rawOutputThroughput: ~"
             << rawOutputThroughput << "Mb/~"
             << static_cast<int>(static_cast<double>(rawOutputThroughput) / 8.389) << "MiB/~"
             << (rawOutputThroughput / 8) << "MB/sec"
             << endl;

        // Queue all buffers
        for (unsigned int i = 0; i < buffers.size(); ++i) {
            v4l2_buffer buf{};
            buf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
            buf.memory = V4L2_MEMORY_MMAP;
            buf.index = i;
            if (xioctl(fd, VIDIOC_QBUF, &buf) == -1) {
                throw_errno("VIDIOC_QBUF");
            }
        }

        // Start streaming
        v4l2_buf_type type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
        if (xioctl(fd, VIDIOC_STREAMON, &type) == -1) {
            throw_errno("VIDIOC_STREAMON");
        }
        cerr << "[cap" << index << "] Initialized V4L2 device: " << devicePath << endl;
    }
};

// parse optional args and collect device names
static void parse_cli_or_die(int argc, const char** argv) {
    double opt_fps = allDevicesTargetFramerate; // default remains the global default
    const char* opt_devices = nullptr;          // optional comma-separated list

    struct poptOption optionsTable[] = {
        { "fps",     'f',    POPT_ARG_DOUBLE,   &opt_fps,      0,    "Target framerate for all devices",                        "FPS" },
        { "devices", 'd',    POPT_ARG_STRING,   &opt_devices,  0,    "V4L2 device(s): /dev/video0 or /dev/video0,/dev/video1",  "DEV[,DEV]" },
        { "help",    'h',    POPT_ARG_NONE,     nullptr,       'h',  "Show help and exit",                                      nullptr },
        { nullptr,   0,      0,                 nullptr,       0,    nullptr,                                                   nullptr }
    };

    poptContext pc = poptGetContext(argv[0], argc, argv, optionsTable, 0);
    int rc;
    while ((rc = poptGetNextOpt(pc)) >= 0) {
        // values written directly to opt variables
    }
    if (rc < -1) {
        std::fprintf(stderr, "[main] Error parsing options: %s: %s\n",
                     poptBadOption(pc, POPT_BADOPTION_NOALIAS), poptStrerror(rc));
        poptPrintUsage(pc, stderr, 0);
        std::exit(1);
    }

    devNames.clear();
    if (opt_devices && *opt_devices) {
        std::string list(opt_devices);
        size_t start = 0;
        while (start <= list.size()) {
            size_t pos = list.find(',', start);
            std::string token = (pos == std::string::npos)
                                ? list.substr(start)
                                : list.substr(start, pos - start);
            token = trim_copy(token);
            if (!token.empty()) devNames.emplace_back(token);
            if (pos == std::string::npos) break;
            start = pos + 1;
        }
        const char* extra = nullptr;
        while ((extra = poptGetArg(pc)) != nullptr) {
            std::fprintf(stderr, "[main] Warning: ignoring extra device '%s' because --devices was specified\n", extra);
        }
    } else {
        const char* arg = nullptr;
        while ((arg = poptGetArg(pc)) != nullptr) {
            devNames.emplace_back(arg);
        }
    }
    poptFreeContext(pc);

    if (devNames.size() == 1) {
        isDualInput = false;
    } else if (devNames.size() == 2) {
        isDualInput = true;
    } else {
        std::fprintf(stderr, "[main] Usage:\n");
        std::fprintf(stderr, "  %s [options] --devices=</dev/video0>[,/dev/video1]\n", argv[0]);
        std::fprintf(stderr, "  %s [options] </dev/video0> [/dev/video1]\n", argv[0]);
        std::fprintf(stderr, "Options:\n");
        std::fprintf(stderr, "  -f, --fps=<FPS>   Target framerate for all devices (default: %.3f)\n", allDevicesTargetFramerate);
        std::fprintf(stderr, "  -d, --devices=<DEVICE(s)>  Comma-separated devices, e.g. /dev/video0 or /dev/video0,/dev/video1\n");
        std::exit(1);
    }

    allDevicesTargetFramerate = opt_fps;

    std::fprintf(stderr, "[main] Parsed options: --fps=%.3f, --devices=%s%s%s\n",
                  allDevicesTargetFramerate,
                  devNames[0].c_str(),
                  isDualInput ? "," : "",
                  isDualInput ? devNames[1].c_str() : "");
}

int main(int argc, char** argv) {
    try {
        parse_cli_or_die(argc, const_cast<const char**>(argv));

        cerr << "[main] Initializing..\n";

        Device devMain(devNames[0], 0, /*force_format=*/3, allDevicesTargetFramerate, /*isTC358743=*/true);
        devMain.init();

        std::unique_ptr<Device> devAlt;
        if (isDualInput) {
            devAlt = std::make_unique<Device>(devNames[1], 1, /*force_format=*/3, allDevicesTargetFramerate, /*isTC358743=*/true);
            devAlt->init();
        }

        shouldLoop.store(true);
        std::this_thread::sleep_for(std::chrono::milliseconds(1));

        MicroStopwatch sw;
        std::this_thread::sleep_for(std::chrono::milliseconds(1));

        // Warm-up: capture and discard some frames
        for (int i = 0; i < 60; ++i) {
            if (isDualInput) {
                background_task_cap_main = std::async(std::launch::async, [&] { return devMain.get_frame(); });
                background_task_cap_alt  = std::async(std::launch::async, [&] { return devAlt->get_frame(); });
                background_task_cap_main.wait();
                background_task_cap_alt.wait();
            } else {
                background_task_cap_main = std::async(std::launch::async, [&] { return devMain.get_frame(); });
                background_task_cap_main.wait();
            }
        }

        cerr << "\n[main] Starting main loop now\n";
        while (shouldLoop.load()) {
            if (!devMain.realAndTargetRatesMatch) sw.start();

            background_task_cap_main = std::async(std::launch::async, [&] { return devMain.get_frame(); });
            const int rc = background_task_cap_main.get();
            if (rc != 0) break;

            std::fwrite(devMain.outputFrame.data(), sizeof(unsigned char), static_cast<size_t>(devMain.startingSize), stdout);

            if (!devMain.realAndTargetRatesMatch) {
                const double elapsed = sw.elapsedMicros();
                if (elapsed < devMain.targetFrameDelayMicros) {
                    const auto to_sleep = static_cast<long>(devMain.targetFrameDelayMicros - elapsed);
                    std::this_thread::sleep_for(std::chrono::microseconds(std::max<long>(0, to_sleep)));
                }
            }
        }

        std::this_thread::sleep_for(std::chrono::seconds(1));
        return 0;
    } catch (const std::exception& ex) {
        std::fprintf(stderr, "Fatal error: %s\n", ex.what());
        return 1;
    }
}
